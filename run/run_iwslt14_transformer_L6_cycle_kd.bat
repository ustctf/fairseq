python train.py F:\Data_Models\NMT\iwslt14.tokenized.de-en --clip-norm 0.0 --min-lr 1e-09  --max-tokens 4096 --share-decoder-input-output-embed --arch transformer_iwslt_de_en_L6 --save-dir F:\Data_Models\NMT\ckpts\IWSLT14_DE_EN_L6_CYCLE_12k_kd_ --criterion kd_cross_entropy  --label-smoothing 0.1 --lr-scheduler cosine  --cosine-cycle-steps 12000 --kd-trade-off 0.5 --start-ensemble-training-cycle 3 --teachers-cnt 3 --kd-temperature 1.0 --optimizer adam --adam-betas "(0.9, 0.98)" --lr 0.001 --warmup-init-lr 1e-07 --warmup-updates 4000 --max-update 90000  